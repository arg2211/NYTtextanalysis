race.fact = c(1, 1), polviews = (4, 4))))
predict(logit1, type = "response", newdata = data.frame(bdiscr = c(0, 1), age = c(46, 46), age.sq = c(2116, 2116),
educ = c(12, 16), realinc = c(25000, 25000), acqmyrac = c(2, 2),
race.fact = c(1, 1), polviews = c(4, 4))))
predict(logit1, type = "response", newdata = data.frame(bdiscr = c(0, 1), age = c(46, 46), age.sq = c(2116, 2116),
educ = c(12, 16), realinc = c(25000, 25000), acqmyrac = c(2, 2),
race.fact = c(1, 1), polviews = c(4, 4)))
class(race.fact)
class(r2$race.fact)
predict(logit1, type = "response", newdata = data.frame(bdiscr = c(0,0), age = c(46,46), age.sq = c(2116, 2116),
educ = c(16,16), realinc = c(25000,25000), acqmyrac = c(2,2),
race.fact = c(1,2), polviews = (4, 4)))
predict(logit1, type = "response", newdata = data.frame(bdiscr = c(0,0), age = c(46,46), age.sq = c(2116, 2116),
educ = c(16,16), realinc = c(25000,25000), acqmyrac = c(2,2),
race.fact = c(1,2), polviews = c(4, 4)))
predict(logit1, type = "response", newdata = data.frame(bdiscr = c(1,1), age = c(46,46), age.sq = c(2116, 2116),
educ = c(16,16), realinc = c(25000,25000), acqmyrac = c(2,2),
race.fact = c(2,2), polviews = c(4, 4)))
logit1 = glm(bmotiv ~ bdiscr + age + age.sq + educ + realinc + acqmyrac +
relevel(race.fact, ref=1) + polviews, r2, family=binomial)
predict(logit1, type = "response", newdata = data.frame(bdiscr = c(0, 1), age = c(46, 46), age.sq = c(2116, 2116),
educ = c(12, 16), realinc = c(25000, 25000), acqmyrac = c(2, 2),
race.fact = c(1, 1), polviews = c(4, 4)))
library(stargazer)
stargazer(lm4, logit1, title="Regression Results", align=TRUE,
dep.var.labels=c("Ineq Due to Lack of Motivation"),
covariate.labels=c("Ineq Due to Discrimination", "Age", "Age Squared",
"Education", "Income", "Race of Acquaintances",
"Race - Black", "Race - Other", "Political Views"),
no.space=TRUE, column.labels=c("Multiple Reg", "Logit"),
dep.var.caption="", model.numbers=FALSE, type = "text", omit = "Constant")
lm5 = lm(bmotiv ~ bdiscr + age + age.sq + educ + realinc + acqmyrac + polviews, r2)
summary(lm5)
r2$yhat <- lm5$fitted # or equivalently sub$yhat <- predict(lpm.romance)
r2$resids <- lm5$residuals
truehist(r2$resids, col = "gold", yaxt = "n", cex.axis = 0.8, xlab = "Residuals")
curve(dnorm(x, mean = mean(r2$resids), sd = sd(r2$resids)),
lwd = 4, col = "orangered", add=T)
logit2 = glm(bmotiv ~ bdiscr + age + age.sq + educ + realinc + acqmyrac + polviews, r2, family=binomial)
summary(logit2)
predict(logit2, type = "response", newdata = data.frame(bdiscr = c(0, 1), age = c(46, 46), age.sq = c(2116, 2116),
educ = c(12, 16), realinc = c(25000, 25000), acqmyrac = c(2, 2),
polviews = c(4, 4)))
predict(logit2, type = "response", newdata = data.frame(bdiscr = c(0,0), age = c(46,46), age.sq = c(2116, 2116),
educ = c(16,16), realinc = c(25000,25000), acqmyrac = c(2,2),
polviews = c(4, 4)))
predict(logit2, type = "response", newdata = data.frame(bdiscr = c(1,1), age = c(46,46), age.sq = c(2116, 2116),
educ = c(16,16), realinc = c(25000,25000), acqmyrac = c(2,2),
polviews = c(4, 4)))
pred.dat <- with(r2, expand.grid(
bdiscr = sort(unique(bdiscr)),
age = mean(age),
age.sq = mean(age.sq),
educ = mean(educ),
realinc = mean(realinc),
acqmyrac = sort(unique(acqmyrac)),
polviews = mean(polviews)))
predProb(logit2, predData = pred.dat, ci = F)
pred.dat <- with(r2, expand.grid(
bdiscr = sort(unique(bdiscr)),
age = mean(age),
age.sq = mean(age.sq),
educ = mean(educ),
realinc = mean(realinc),
acqmyrac = sort(unique(acqmyrac)),
polviews = sort(unique(polviews)))
pred.dat <- with(r2, expand.grid(
bdiscr = sort(unique(bdiscr)),
age = mean(age),
age.sq = mean(age.sq),
educ = mean(educ),
realinc = mean(realinc),
acqmyrac = sort(unique(acqmyrac)),
polviews = sort(unique(polviews))))
pred.dat <- with(r2, expand.grid(
bdiscr = sort(unique(bdiscr)),
age = mean(age),
age.sq = mean(age.sq),
educ = mean(educ),
realinc = mean(realinc),
acqmyrac = sort(unique(acqmyrac)),
polviews = sort(unique(polviews))))
predProb(logit2, predData = pred.dat, ci = F)
library(visreg)
plot(logit2)
library(visreg)
visreg(logit2, xvar="bdiscr", by="bmotiv", overlay=T, partial=F, legend=F,
xlab="Ineq. Due to Discrimination", ylab="Ineq. Due to Lack of Motivation",
scale="response", line = list(col = c("cyan3", "purple3", "red", "blue", "gray55")))
visreg(logit2, xvar="bdiscr", by="bmotiv", overlay=T, partial=F, legend=F,
xlab="Ineq. Due to Discrimination", ylab="Ineq. Due to Lack of Motivation",
scale="response", type = "conditional",
line = list(col = c("cyan3", "purple3", "red", "blue", "gray55")))
visreg(logit2, xvar="bdiscr", by="bmotiv", overlay=T, partial=F, legend=F,
xlab="Ineq. Due to Discrimination", ylab="Ineq. Due to Lack of Motivation",
scale="response", type = "conditional", alpha = .90,
line = list(col = c("cyan3", "purple3", "red", "blue", "gray55")))
visreg(logit2, xvar="bdiscr", by="bmotiv", overlay=T, partial=F, legend=F,
xlab="Ineq. Due to Discrimination", ylab="Ineq. Due to Lack of Motivation",
scale="response", type = "conditional", alpha = .90,
line = list(col = c("cyan3", "purple3")))
visreg(logit2, xvar="bdiscr", by="bmotiv", overlay=T, partial=F, legend=F,
xlab="Ineq. Due to Discrimination", ylab="Ineq. Due to Lack of Motivation",
scale="response", type = "conditional", alpha = .90,
line = list(col = c("cyan3", "purple3", "gray55")))
legend("bottomleft", lwd = 2, c("1", "2", "3", "4", "5"), col = c("cyan3", "purple3", "red", "blue", "gray55"), cex = 0.8)
library(plm)
library(QMSS)
d=read.csv(file.choose()) ## choose "panel-for-R.csv" and more information on variables are here: http://sda.berkeley.edu/sdaweb/analysis/?dataset=gss06panelw3 ##
vars <- c("idnum","panelwave","affrmact","race", "intrace1")
pd.sub <- d[, vars]
pd.sub$black = ifelse(pd.sub$race==2, 1, 0)
pd.sub$intblack = ifelse(pd.sub$intrace1==2, 1, 0)
pd.sub$r.affact = 5-pd.sub$affrmact
pd.sub$year= ifelse(pd.sub$panelwave==3, 1, 0)
lm1 <- lm(r.affact ~ black + intblack + as.factor(panelwave),  data = pd.sub)
summary(lm1)
clusterSE(fit = lm1, cluster.var = "idnum", data=pd.sub)
plm1 <- plm(r.affact ~ black + intblack + year,  index = c("idnum", "panelwave"),  model = "fd", data = pd.sub)
summary(plm1)
clusterSE(fit = plm1, cluster.var = "idnum", data=pd.sub)
pd.sub$fourvsall= ifelse(pd.sub$r.affact==4, 1, 0)
pd.sub$fourthreevsall= ifelse(pd.sub$r.affact>=3, 1, 0)
pd.sub$fourthreetwovsone= ifelse(pd.sub$r.affact>=2, 1, 0)
plm2 <- plm(fourvsall ~ black + intblack + year,  index = c("idnum", "panelwave"),  model = "fd", data = pd.sub)
plm3 <- plm(fourthreevsall ~ black + intblack + year,  index = c("idnum", "panelwave"),  model = "fd", data = pd.sub)
plm4 <- plm(fourthreetwovsone ~ black + intblack + year,  index = c("idnum", "panelwave"),  model = "fd", data = pd.sub)
summary(plm4)
library(stargazer)
stargazer(plm1, plm2, plm3, plm4, type = "text")
pd.sub$d.intblack = firstD(intblack, idnum, pd.sub )
table(pd.sub$d.intblack)
pd.sub$bw=ifelse(pd.sub$d.intblack==-1,1,0)
pd.sub$wb=ifelse(pd.sub$d.intblack==1,1,0)
pd.sub$d.r.affact=firstD(r.affact, idnum, pd.sub )
summary(lm(intblack ~ black, pd.sub))
pd.sub$d.black = firstD(black, idnum, pd.sub )
table(pd.sub$d.black)
summary(lm(d.r.affact ~ bw, pd.sub, subset=black==0))
vars2 = c("colsci", "colscinm", "advfront", "scibnfts", "natsci", "educ", "relig", "fund", "idnum", "panelwave", "id", "year")
v = pan[,vars2]
table(v$panelwave, v$advfront)
prop.table(table(v$panelwave, v$advfront))
table(v$panelwave, v$natsci)
prop.table(table(v$panelwave, v$natsci))
library(plyr)
library(devtools)
library(QMSS)
v$scinec = 5-v$advfront
lm2 <- lm(natsci ~ scinec + as.factor(panelwave), v)
summary(lm2)
sci.pool2 <- plm(natsci ~ scinec + as.factor(panelwave), index = c("idnum", "panelwave"), model = "pooling", data = v)
summary(sci.pool2)
clusterSE(fit = lm2, cluster.var = "idnum", data = v)
pan=read.csv(file.choose()) ## choose panel-for-R.csv
vars2 = c("colsci", "colscinm", "advfront", "scibnfts", "natsci", "educ", "relig", "fund", "idnum", "panelwave", "id", "year")
v = pan[,vars2]
table(v$panelwave, v$advfront)
prop.table(table(v$panelwave, v$advfront))
library(plyr)
library(devtools)
library(QMSS)
v$scinec = 5-v$advfront
lm2 <- lm(natsci ~ scinec + as.factor(panelwave), v)
summary(lm2)
clusterSE(fit = lm2, cluster.var = "idnum", data = v)
v <- ddply(v, "idnum", mutate, d.scinec = firstD(scinec), d.natsci = firstD(natsci))
table(v$d.scinec)
prop.table(table(v$d.scinec))
table(v$d.natsci)
prop.table(table(v$d.natsci))
plm2 <- plm(natsci ~ scinec + as.factor(panelwave), index = c("idnum", "panelwave"), model = "fd", data = v)
summary(plm2)
clusterSE(fit = plm2, cluster.var = "idnum", data=v)
v$bsci = 4-v$scibnfts
v <- ddply(v, "idnum", mutate, d.bsci = firstD(bsci))
table(v$d.bsci)
prop.table(table(v$d.bsci))
plm3 <- plm(natsci ~ scinec + as.factor(panelwave) + as.factor(bsci), index = c("idnum", "panelwave"), model = "fd", data = v)
summary(plm3)
library(stargazer)
stargazer(lm2, plm2, plm3, title="Regression Results", align=TRUE, dep.var.labels=c("Federal Spending on Scientific Research"), covariate.labels=c("Pro Sci","2008","2010","Ben=Harm","Ben>Harm"), no.space=TRUE, column.labels=c("OLS", "First Diff A", "First Diff B"), dep.var.caption="", model.numbers=FALSE, type = "text", omit = "Constant")
install.packages("streamR")
library(streamR)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "gYIxV6TdEf9glxYWlGSGdBAiF"
consumerSecret <- "QIRynpLw0P6elikgsRyQeM7SzencY0Q1oGDwfb4zvzWpGBUe1K"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
library(RCurl)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "gYIxV6TdEf9glxYWlGSGdBAiF"
consumerSecret <- "QIRynpLw0P6elikgsRyQeM7SzencY0Q1oGDwfb4zvzWpGBUe1K"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
load("my_oauth")
library(ROAuth)
install.packages("ROAuth")
library(ROAuth)
library(RCurl)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "gYIxV6TdEf9glxYWlGSGdBAiF"
consumerSecret <- "QIRynpLw0P6elikgsRyQeM7SzencY0Q1oGDwfb4zvzWpGBUe1K"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
library(streamR)
filterStream("tweets.json", track = c("women", "men", timeout = 10, oauth = my_oauth))
filterStream("tweets.json", track = c("women", "men"), timeout = 10, oauth = my_oauth)
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
c( length(grep("women", tweets.df$text, ignore.case = TRUE)),
length(grep("men", tweets.df$text, ignore.case = TRUE)) )
View(tweets.df)
table(tweets.df)
View(tweets.df)
list(tweets.df)
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 10,
oauth = my_oauth)
tweets.df <- parseTweets("tweetsUS.json", verbose = FALSE)
library(ggplot2)
library(grid)
map.data <- map_data("state")
install.packages("maps")
library(maps)
map.data <- map_data("state")
points <- data.frame(x = as.numeric(tweets.df$lon), y = as.numeric(tweets.df$lat))
points <- points[points$y > 25, ]
ggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = "white",
color = "grey20", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) +
theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(),
axis.title = element_blank(), panel.background = element_blank(), panel.border = element_blank(),
panel.grid.major = element_blank(), plot.background = element_blank(),
plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), "lines")) + geom_point(data = points,
aes(x = x, y = y), size = 1, alpha = 1/5, color = "darkblue")
table(gss$race)
prop.table(table(gss$race))
find.package("devtools")
library(devtools)
find_rtools()
find.package("KernSmooth")
library(KernSmooth)
shiny::runApp('GitHub/DataViz/Assignment4/shinyapp')
setwd("~/GitHub/NYTtextanalysis/data/random2015dates")
options(stringsAsFactors = FALSE)
nyt.merged <- read.csv("nyt.merged.csv")
library(tm)
onlytext <- paste(nyt.merged$TEXT, collapse = " ", stringsAsFactors = FALSE)
onlytextcorpus <- Corpus(VectorSource(onlytext))
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})
otc <- tm_map(onlytextcorpus, content_transformer(tolower)) #need to use content_transformer with tolower because of bug in newer version of tm package
otc <- tm_map(otc, stripWhitespace)
otc2 <- tm_map(otc, removePunctuation)
otc2 <- tm_map(otc2, removeNumbers)
otc2 <- tm_map(otc2, toSpace, "-")
otc2 <- tm_map(otc2, toSpace, ":")
otc2 <- tm_map(otc2, toSpace, "%")
otc2 <- tm_map(otc2, toSpace, ",")
otc2 <- tm_map(otc2, removeWords, stopwords("english"))
otc2 <- tm_map(otc2, removeWords, c("url")) #insert words that you want to remove from corpus where "x" is
otc2 <- tm_map(otc2, stripWhitespace)
otcstem <- tm_map(otc2, stemDocument) #uses tm package stemming
dtm.otc <- DocumentTermMatrix(otc)
dtm.m.otc <- as.matrix(dtm.otc)
dtm.otc # gives number of terms in documents # 131,986 terms
dtm.otc2 <- DocumentTermMatrix(otc2)
dtm.m.otc2 <- as.matrix(dtm.otc2)
dtm.otc2 # 69,525 terms
dtm.stem <- DocumentTermMatrix(otcstem)
dtm.m.otcstem <- as.matrix(dtm.stem)
dtm.stem # 49,377 terms
freq.otc <- colSums(dtm.m.otc)
freq.otc <- sort(freq.otc, decreasing = TRUE)
count.otc <- rowSums(dtm.m.otc)
count.otc # 1,400,486 words
freq.otc2 <- colSums(dtm.m.otc2)
freq.otc2 <- sort(freq.otc2, decreasing = TRUE)
count.otc2 <- rowSums(dtm.m.otc2)
count.otc2 # 945,003 words
freq.otcstem <- colSums(dtm.m.otcstem)
freq.otcstem <- sort(freq.otcstem, decreasing = TRUE)
count.stem <- rowSums(dtm.m.otcstem)
count.stem # 942,968
library(wordcloud)
library(RColorBrewer)
require(quanteda)
class(onlytext) # need to begin with a character object
sentences <- tokenize(onlytext, what = "sentence")
sentences <- toLower(sentences, keepAcronyms = FALSE) # make all sentences lowercase
sentences.df <- as.data.frame(unlist(sentences)) # create dataframe of lowercase sentences
colnames(sentences.df) = c("all") # rename column in dataframe to "all"
sentences.df <- as.data.frame(apply(sentences.df, 2, function(y) gsub("'", "", y)))
sentences.df <- as.data.frame(apply(sentences.df, 2, function(y) gsub(",", "", y)))
sentences.df <- as.data.frame(apply(sentences.df, 2, function(y) gsub("^false", "", y)))
sentences.df$men <- ifelse(grepl("\\b(guys?|spokesm[ae]ns?|chairm[ae]ns?|m[ae]ns?|congressm[ae]ns?|him|hes?|his|boys?|boyfriends?|brothers?|dads?|dudes?|fathers?|gentlem[ae]ns?|gods?|grandfathers?|grandpas?|grandsons?|grooms?|groomsmen|himself|hisself|husbands?|kings?|males?|mr|mr.|nephews?|priests?|princes?|sons?|uncles?|widowers?)\\b", sentences.df$all, ignore.case = TRUE), 1, 0)
sentences.df$women <- ifelse(grepl("\\b(heroines?|spokeswom[ae]ns?|chairwom[ae]ns?|congresswom[ae]ns?|wom[ae]ns?|actresss?|actresses|shes?|her|aunts?|brides?|daughters?|females?|girls?|girlfriends?|goddesss?|goddesses|granddaughters?|grandmas?|grandmothers?|herself|ladies|ladys?|moms?|mothers?|mrs|mrs.|ms|ms.|nieces?|priestesss?|priestesses|princesss?|princesses|queens?|sisters?|waitresss?|waitresses|widows?|wifes?|wives)\\b", sentences.df$all, ignore.case = TRUE), 1, 0)
sentences.df$both <- ifelse((sentences.df$men==1 & sentences.df$women==1), 1, 0)
sentences.df$none <- ifelse((sentences.df$men==0 & sentences.df$women==0), 1, 0)
sum(sentences.df$none) # 55,422 sentences that are about neither men nor women
sum(sentences.df$both) # 3,064 sentences that contain words about both men and women
sum(sentences.df$men) # 24,233 sentences that contain a 'man' word
sum(sentences.df$women) # 9,724 sentences that contain a 'woman' word
t.test(sentences.df$men,sentences.df$women)
prop.test(x=c(24233,9724),n=c(86315,86315))
s.men <- subset(sentences.df, men==1 & women!=1)
s.women <- subset(sentences.df, women==1 & men!=1)
corpus.men <- paste(s.men$all, collapse = " ", stringsAsFactors = FALSE)
corpus.men <- Corpus(VectorSource(corpus.men))
corpus.women <- paste(s.women$all, collapse = " ", stringsAsFactors = FALSE)
corpus.women <- Corpus(VectorSource(corpus.women))
library(SnowballC)
library(Rcampdf)
fp <- file.path(".", "sentences")
dir(fp) # tells you what files are in the filepath directory
docs <- Corpus(DirSource(fp))
docs2 <- Corpus(DirSource(fp))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, toSpace, "-")
docs <- tm_map(docs, toSpace, ":")
docs <- tm_map(docs, toSpace, "창")
docs <- tm_map(docs, toSpace, "찾")
docs <- tm_map(docs, toSpace, "%")
docs <- tm_map(docs, removeWords, c("url", "false"))
docs <- tm_map(docs, removeWords, stopwords("english")) # NEED TO FIX THIS - WANT TO KEEP HE,SHE,ETC.
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
docs2 <- tm_map(docs2, content_transformer(tolower))
docs2 <- tm_map(docs2, removePunctuation)
docs2 <- tm_map(docs2, removeNumbers)
docs2 <- tm_map(docs2, toSpace, "-")
docs2 <- tm_map(docs2, toSpace, ":")
docs2 <- tm_map(docs2, toSpace, "창")
docs2 <- tm_map(docs2, toSpace, "찾")
docs2 <- tm_map(docs2, toSpace, "%")
docs2 <- tm_map(docs2, toSpace, ",")
docs2 <- tm_map(docs2, removeWords, c("url", "false"))
docs2 <- tm_map(docs2, stemDocument)
docs2 <- tm_map(docs2, stripWhitespace)
docs2 <- tm_map(docs2, PlainTextDocument)
docs.dtm <- DocumentTermMatrix(docs)
docs.dtm # 34% sparsity, 2 documents, 28,574 terms
docs.dtm.df = as.data.frame(as.matrix(docs.dtm))
docs2.dtm <- DocumentTermMatrix(docs2)
docs2.dtm[1,] #24,083 non-sparse + 4,561 sparse terms for men
docs2.dtm.df = as.data.frame(as.matrix(docs2.dtm))
findFreqTerms(docs.dtm, lowfreq=500) # lowest freq = 500 times
freq.docs <- colSums(docs.dtm.df)
freq.docs <- sort(freq.docs, decreasing = TRUE)
count.docs <- rowSums(docs.dtm.df)
count.docs #263,656 words in sentences about men & 79,442 words in sentences about women
freq.docs2 <- colSums(docs2.dtm.df)
freq.docs2 <- sort(freq.docs2, decreasing = TRUE)
count.docs2 <- rowSums(docs2.dtm.df)
count.docs2 #378,667 words in sentences about men & 116,311 words in sentences about women
rownames(docs.dtm.df) = c("men","women")
docs.m <- docs.dtm.df[1,]
docs.m <- sort(docs.m, decreasing = TRUE)
docs.w <- docs.dtm.df[2,]
docs.w <- sort(docs.w, decreasing = TRUE)
freq.docs.m <- colSums(docs.m)
freq.docs.m <- sort(freq.docs.m, decreasing = TRUE)
count.docs.m <- rowSums(docs.m)
count.docs.m # 263,656
freq.docs.w <- colSums(docs.w)
freq.docs.w <- sort(freq.docs.w, decreasing = TRUE)
count.docs.w <- rowSums(docs.w)
count.docs.w # 79,442
prop.test(x=c(24233,9724),n=c(263656,79442))
rownames(docs2.dtm.df) = c("men","women")
docs2.m <- docs2.dtm.df[1,]
docs2.m <- sort(docs2.m, decreasing = TRUE)
docs2.w <- docs2.dtm.df[2,]
docs2.w <- sort(docs2.w, decreasing = TRUE)
freq.docs2.m <- colSums(docs2.m)
freq.docs2.m <- sort(freq.docs2.m, decreasing = TRUE)
count.docs2.m <- rowSums(docs2.m)
count.docs2.m #378,667
freq.docs2.w <- colSums(docs2.w)
freq.docs2.w <- sort(freq.docs2.w, decreasing = TRUE)
count.docs2.w <- rowSums(docs2.w)
count.docs2.w #116,311
docs.tdm.df <- t(docs.dtm.df)
docs2.tdm.df <- t(docs2.dtm.df)
cor(docs.tdm.df)
cor(docs2.tdm.df)
terms <-DocumentTermMatrix(docs,control=list(weighting=function(x) weightTfIdf(x,normalize=FALSE)))
terms # 2 docs, 66% sparse
terms.df <- as.data.frame(as.matrix(terms))
terms.t <- t(terms.df)
terms.t.df <- as.data.frame(terms.t)
colnames(terms.t.df) = c("men","women")
terms.t.df$total <- terms.t.df$men + terms.t.df$women
summing <- function(x) x/sum(x, na.rm=T)
docs.dtm.df.t_new <- apply(terms.t, 2, summing)
colnames(docs.dtm.df.t_new) = c("men","women")
head(docs.dtm.df.t_new) # this is good stuff
docs.dtm.df.t_new <- as.data.frame(docs.dtm.df.t_new)
docs.dtm.df.t_new$menP <- docs.dtm.df.t_new$men*100
docs.dtm.df.t_new$womenP <- docs.dtm.df.t_new$women*100
docs.dtm.df.t_new$ratio = docs.dtm.df.t_new$men - docs.dtm.df.t_new$women
sort.men <- docs.dtm.df.t_new[order(-docs.dtm.df.t_new$ratio) , ]
sort.men[1:15, ]
require(RWeka)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
docs.tdm.bi <- TermDocumentMatrix(docs, control = list(tokenize = BigramTokenizer))
docs.tdm.bi.df <- as.data.frame(as.matrix(docs.tdm.bi))
colnames(docs.tdm.bi.df) <- c("men","women")
count.bi <- colSums(docs.tdm.bi.df)
count.bi # 275,489 bigrams for men + 82,310 bigrams for women
freq.bi <- rowSums(docs.tdm.bi.df)
freq.bi <- sort(freq.bi, decreasing = TRUE)
docs.tdm.tri <- TermDocumentMatrix(docs, control = list(tokenize = TrigramTokenizer))
docs.tdm.tri.df <- as.data.frame(as.matrix(docs.tdm.tri))
colnames(docs.tdm.tri.df) <- c("men","women")
count.tri <- colSums(docs.tdm.tri.df)
count.tri # 275,488 trigrams for men + 82,309 trigrams for women
freq.tri <- rowSums(docs.tdm.tri.df)
freq.tri <- sort(freq.tri, decreasing = TRUE)
docs2.tdm.bi <- TermDocumentMatrix(docs2, control = list(tokenize = BigramTokenizer))
docs2.tdm.bi.df <- as.data.frame(as.matrix(docs2.tdm.bi))
colnames(docs2.tdm.bi.df) <- c("men","women")
count2.bi <- colSums(docs2.tdm.bi.df)
count2.bi # 483,230 bigrams for men + 144,159 bigrams for women
freq2.bi <- rowSums(docs2.tdm.bi.df)
freq2.bi <- sort(freq2.bi, decreasing = TRUE)
docs2.tdm.tri <- TermDocumentMatrix(docs2, control = list(tokenize = TrigramTokenizer))
docs2.tdm.tri.df <- as.data.frame(as.matrix(docs2.tdm.tri))
colnames(docs2.tdm.tri.df) <- c("men","women")
count2.tri <- colSums(docs2.tdm.tri.df)
count2.tri # 483,229 trigrams for men + 144,158 trigrams for women
freq2.tri <- rowSums(docs2.tdm.tri.df)
freq2.tri <- sort(freq2.tri, decreasing = TRUE)
prop.test(x=c(254,1048),n=c(4269,12138))
prop.test(x=c(1048,254),n=c(12138,4269))
prop.test(x=c(1048,254),n=c(483230,144159))
prop.test(x=c(12138,4269),n=c(483230,144159))
prop.test(x=c(1048,254),n=c(43554,12367))
prop.test(x=c(12138,4269),n=c(43554,12367))
prop.test(x=c(1048,254),n=c(12138,4269))
prop.test(x=c(1048,254),n=c(483230,144159))
prop.test(x=c(1048,254),n=c(43554,12367))
prop.test(x=c(12138,4269),n=c(483230,144159))
prop.test(x=c(12138,4269),n=c(43554,12367))
docs.dtm.s <- removeSparseTerms(docs.dtm, 0.20) # This makes a matrix that is 20% empty space, maximum.
library(cluster)
docs.m.s <- removeSparseTerms(docs.m, 0.20) # This makes a matrix that is 20% empty space, maximum.
class(docs.dtm.s)
docs.dtm.m <- DocumentTermMatrix(docs.m)
docs.dtm.s # 9,219 terms, 2 docs, 0% sparse
docs.dtm.s <- removeSparseTerms(docs.dtm, 0.20) # This makes a matrix that is 20% empty space, maximum.
docs.dtm.s # 9,219 terms, 2 docs, 0% sparse
docs.dtm.m <- docs.dtm.s[1,]
docs.dtm.m
docs.dtm.m <- docs.dtm[1,]
docs.dtm.m
docs.m.s <- removeSparseTerms(docs.dtm.m, 0.20) # This makes a matrix that is 20% empty space, maximum.
docs.m.s # 9,219 terms, 2 docs, 0% sparse
docs.dtm.m <- docs.dtm.s[1,]
docs.m.s <- removeSparseTerms(docs.dtm.m, 0.20) # This makes a matrix that is 20% empty space, maximum.
d <- dist(t(docs.dtm.s), method="euclidian")
fit <- hclust(d=d, method="ward")
fit
plot(fit, hang=-1)
View(docs.dtm.df)
library(ggplot2)
library(fpc)
kfit <- kmeans(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
docs.dtm.s.df <- as.data.frame(docs.dtm.s)
docs.dtm.s.df <- as.data.frame(t(docs.dtm.s))
View(docs.dtm.df)
View(docs.tdm.df)
docs.dtm.g <- DocumentTermMatrix(docs, control=list(wordLengths=c(3, 20)))
docs.dtm.g
docs.dtm.g <- DocumentTermMatrix(docs, control=list(wordLengths=c(3, 15)))
docs.dtm.g.s <- removeSparseTerms(docs.dtm.g, 0.15) # This makes a matrix that is 20% empty space, maximum.
docs.dtm.g.s # 9,040 terms, 2 docs, 0% sparse
docs.dtm.g <- DocumentTermMatrix(docs,
control=list(wordLengths=c(3, 15)),
bounds=list(2, Inf))
docs.dtm.g <- DocumentTermMatrix(docs,
control=list(wordLengths=c(3, 15)),
bounds=list(2, 2))
docs.dtm.g <- DocumentTermMatrix(docs,
control=list(wordLengths=c(3, 15)),
bounds=list(global=c(2, 2)))
docs.dtm.g.s <- removeSparseTerms(docs.dtm.g, 0.15)
docs.dtm.g.s # 9,040 terms, 2 docs, 0% sparse
class(docs.dtm.s)
class(docs.tdm.bi)
docs.tdm.bi.s <- removeSparseTerms(docs.tdm.bi, 0.15) # This makes a matrix that is 20% empty space, maximum.
docs.tdm.bi.s # 9,040 terms, 2 docs, 0% sparse
cor(docs.tdm.df)
cor(docs2.tdm.df)
citation("SnowballC")
citation("RWeka")
citation("tm")
citation("quanteda")
citation("wordcloud")
citation("RColorBrewer")
